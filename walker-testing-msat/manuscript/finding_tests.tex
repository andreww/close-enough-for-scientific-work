\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{a4paper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage[colorlinks,linkcolor=blue,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{lineno}

\linespread{1.3}

\title{Finding tests for the Matlab Seismic Anisotropy Toolkit}
\author{Andrew M. Walker\footnote{School of Earth and Environment, 
                   University of Leeds, Leeds, LS2 9JT, UK. \url{a.walker@leeds.ac.uk} }
\and 
             James Wookey\footnote{School of Earth Sciences, 
                    University of Bristol, Queen's Road, Bristol, BS8 1RT, UK.}}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle
\linenumbers


During 2011 and 2012 we created MSAT, the Matlab Seismic Anisotropy
Toolkit \cite{Walker2012c}. We aimed to create a reusable, maintainable and documented
software suite to enable easer modelling of seismic anisotropy. This 
variation of seismic wave speed with direction is a property of many 
Earth materials that offers insight into processes such as the geometry
of cracks (important in hydrocarbon exploration) and the alignment
of crystals (a signature of high temperature deformation in the Earth's
interior). In creating MSAT we brought together existing software
already in use in our lab with new tools. Part of this effort involved
finding suitable tests for the various new and refurbished functions 
within MSAT. It turned out that many of the most useful of these 
functions are re-implementations of software described in published
scientific papers, often from the 1960s, '70s or '80s. We found that 
the example results commonly included in these papers make useful test
cases. Indeed, being able to reproduce these is a key to demonstrating 
scientific reproducibility. In this chapter we discuss some of the choices
we made when designing the test suite for MSAT and point out some of
the pitfalls we discovered during this process. Before discussing the 
tests themselves we provide some background on the scientific problem
the code is designed to solve and why we chose to build and release a 
toolbox to in the first place.

\section{Building MSAT}

Seismologists study the propagation of elastic waves through the Earth (or
sometimes through the Moon or other planets). Analysis of the small surface 
displacement caused by these waves and recorded as seismograms by 
seismometers allows the location and properties of earthquake source 
and the material between the source and the seismometer to be determined.

* Some examples
* But we deal with anisotropy
* seismic waves propagate at different speeds in different directions
* and with three (rather than the familiar two) velocities 
* analysis using seismic anisotropy can give much more information 
about the medium (examples)
* but is more complex

Why build MSAT:

Before thinking about our testing strategy, it's worth first considering why
we wanted to build MSAT in the first place. We already had a large collection 
of existing code that was put together piecemeal, to solve particular scientific
challenges, and this was in use by several lab members. But this code was not
particularly well maintained. We had no central reference version and no easy
way to know who had made what modifications to the code. Furthermore, the 
quality of the code documentation was rather mixed, with some functions coming
with useful documentation and others having ``documentation'' entirely passed on
by word of mouth. The real catalyst for change came from a graduate student 
discovering a bug in one of our functions. This wasn't so shocking. What was 
unfortunate was that the student's office mate had found, isolated and fixed the
same bug two years previously. Once this had been rectified, we set about 
bring our code together into one place with a focus on the following:
\begin{description}

\item[Introducing a consistent API:] as far as possible we wanted users 
to be able to guess the correct function naming, the correct data format 
and the correct order of arguments. To this end we decided to represent 
elasticity consistently as $6\times6$ Matlab arrays (even where fewer
values were needed), to always start argument lists that operate on 
elasticity with the elastic constant matrix followed by the density, and
chose to start all function names with the string `\texttt{MS\_}'.

\item[Include adequate documentation:] we created a documentation template
to be included in all functions that would be directly accessible to the user
the built in \texttt{help} and \texttt{doc} commands and set about the task of
creating this documentation for each function as we updated its API. We 
supplemented this with additional general documentation to introduce 
the toolkit as a whole and provided example code to show how
some common tasks could be undertaken.

\item[Introduce versioning:] we imported the code into a distributed version
control system (git) and created a mechanism to generate numbered 
releases of MSAT. If nothing else this gave us a way of asking our own students
which version of the code they were using.

\item[Update licensing information:] we made sure that all code was consistently 
licensed using a liberal BSD license.

\item[Increase the robustness of the code:] we created an automated test suite 
for MSAT and, as described in the rest of this chapter, set about creating test 
cases. We also peppered the code with runtime checks to try to ensure that
the results we were producing were reasonable. 

\end{description}

This process turned out to be quite a lot of work (two people working part time
for XXX months) but we think the resulting code is both useful and that we 
learned some useful lessons about testing scientific software. The fact that 
we now have a reusable foundation for our work on modelling seismic  
anisotropy has given a boost to our productivity and 
(if the citation rate is anything to go by) the productivity of other groups.


\section{A first test case}

Many rocks are composed of many layers of material with different elastic properties. When
the seismic wavelength (XX-YY km) is significantly longer than the layer thickness ($\sim0.1$--
$100$ m in many sedimentary sequences) we need to be able to describe the effective elastic
properties of the stack of layers to make progress efficiently. MSAT provides a functions designed
to enable the calculation of the effective elasticity of bodies such as these sedimentary sequences
which consist of ``thin periodic layers''. For the simplest case, where each layer is isotropic, the 
method of Backus \cite{Backus1962} is implemented and examination of this approach gives some
useful insight into testing in MSAT.

It's worth starting by thinking about the geometry of the model, as illustrated in Figure \ref{fig:backus}, 
and thinking by about compressional waves propagating in the $x$ direction such that only $\varepsilon_{xx}$
is non-zero. In this case the strain in each layer must be the same, which allows the calculation of each
elastic constant starting from the definition of Hooke's Law for the layered body as a whole and in each layer separately:
\begin{equation}
\langle \sigma \rangle = \langle C \rangle \langle \varepsilon \rangle
\end{equation}
\begin{equation}
\sigma_i = C_i \varepsilon_i
\end{equation}
where $\langle \; \rangle$ indicates a volume average over the layers and the subscripts represent each layer. 
We can write 
\begin{equation}
\langle \sigma \rangle = \sum_i f_i \sigma_i
\end{equation}
\begin{equation}
\langle \sigma \rangle = \sum_i f_i C_i \varepsilon_i
\end{equation}
\begin{equation}
\varepsilon_i =  \langle \varepsilon \rangle
\end{equation}
\begin{equation}
\langle \sigma \rangle = \sum_i f_i C_i \langle \varepsilon \rangle
\end{equation}
\begin{equation}
\langle C \rangle \langle \varepsilon \rangle = \sum_i f_i C_i \langle \varepsilon \rangle
\end{equation}
\begin{equation}
\langle C \rangle = \sum_i f_i C_i 
\end{equation}

* Initially we can think about rays going normal to the layers, this is 
implies that the stress in each layer is constant and we have Voigt (check)
avarage of $C_{33}$. This is our first test (and deserves a Figure)
* Also or the $x$ direction - with must be Reuss
* We also have an argument about symmetry, must be hexagonal. This is our
second test.
* But even together this is not enough - how can we go further?
* Point out that the literature is a good source of tests and these
tests have a special place in confirming scientific reproducibility.
* Argue that "good enough" in this context is sufficiently good to 
reproduce the published work, given the precision of the reported results.

\begin{figure}[htbp]
   \centering
   % NB: need to create this
   % \includegraphics{example.jpg} % requires the graphicx package
   \caption{Some figure with layers highlighting the symmetry (rotational around z) 
                 and fact that the layers must all have the same stress for $\sigma_{zz}$
                 and the same strain for $\sigma_{xx}$}
   \label{fig:backus}
\end{figure}

\section{Building a library of tests}

* Make the point that it is valuable to include tests for all published
examples, not just a subset of them. Note that not doing this has caught
us out. 
* Illustrate this with an example, probably using tensor decomposition 
of Browaeys and Chevrot \cite{Browaeys2004}.
* Sometimes test cases are of exactly the same algorithm - e.g. making
MS\_phasevels go more quickly
* Here we can be more strict with our tolerances - and we are approaching 
the ream of numerical analysis - which is outside the main thrust of this chapter
* But we should note that these tests should be distinct
* Other times we have analytical solutions of simple cases, but again this is 
outside the main thrust of the argument

\section{Defensive programming}

* Comment on the fact that this is not the only way we test MSAT.
* We need to include tests and other code to help maintain high 
standards of software engineering (e.g. fails gracefully if provided 
with invalid data).
* But these test case are generally ease to think about
* And are (to some extent) orthogonal to the scientific problem

\section{Lessons}

* Being able to reproduce previous results is a key part of science
* Tests can automate the process of checking that our code still does 
this.
* Previous published work is a key source of such tests
* But, often, the precision given in this previous work is limited (this
is especially true for older publications, where computational limitations 
were important). Although this can be all we have.
* When turning this previous work into tests, it is valuable to turn all
published results into test cases.
* Sometimes these tests do not come from the first presentation of the 
approach, but from some later use.
* Always include commentary with the test outlining where it comes from
and what it is for - just like for functions - especially where the source of the 
test and the original method differ
* Remember that these are not the only tests code should have, but we
argue that this sort of test case should have a special place in the scientific
method.

\bibliographystyle{is-unsrt}
\bibliography{allpapers} 



\end{document}  